# Timestamp Capture - LLM Usage Brief

**Version**: v3.59.1  
**Purpose**: Guide for LLMs and developers on using the timestamp_capture instrumentation system  
**Location**: `osbot_utils.helpers.timestamp_capture`  
**Repo**: https://github.com/owasp-sbot/OSBot-Utils  
**Install**: `pip install osbot-utils`

---

## Quick Start

### 1. Add @timestamp to Methods You Want to Profile

```python
from osbot_utils.helpers.timestamp_capture.decorators.timestamp import timestamp

class MyProcessor(Type_Safe):
    
    @timestamp
    def process(self, data):
        parsed = self._parse(data)
        result = self._transform(parsed)
        return self._output(result)
    
    @timestamp
    def _parse(self, data):
        # parsing logic
        return parsed_data
    
    @timestamp
    def _transform(self, data):
        # transformation logic
        return transformed_data
    
    @timestamp
    def _output(self, data):
        # output logic
        return final_result
```

### 2. Capture Timing Data

```python
from osbot_utils.helpers.timestamp_capture.Timestamp_Collector import Timestamp_Collector

# The variable MUST be named exactly '_timestamp_collector_'
_timestamp_collector_ = Timestamp_Collector(name="my_profiling_session")

with _timestamp_collector_:
    processor = MyProcessor()
    result = processor.process(data)

# Print results
_timestamp_collector_.print_report()
```

### 3. That's It

The `@timestamp` decorator automatically finds the collector via stack-walking. No need to pass it through function signatures.

> **Tip**: Use `@timestamp(name="custom.metric.name")` to override the default method name with a custom, hierarchical name for better report organization. See [Pattern 4: Custom Metric Names](#pattern-4-custom-metric-names) for details.

---

## Core Concepts

### The Magic Variable Name

The collector is found by walking the call stack and looking for a local variable named exactly `_timestamp_collector_`. This is intentional:

```python
# ✅ CORRECT - Will be found
_timestamp_collector_ = Timestamp_Collector()

# ❌ WRONG - Will NOT be found
collector = Timestamp_Collector()
my_collector = Timestamp_Collector()
timestamp_collector = Timestamp_Collector()
```

### When No Collector Present

If no `_timestamp_collector_` exists in the call stack, decorated methods execute normally with ~3μs overhead (negligible). This means decorators can safely remain in production code.

```python
@timestamp
def my_method(self):
    return 42

# No collector in scope - runs normally, ~3μs overhead
result = my_method()
```

---

## Import Reference

```python
# Core collector
from osbot_utils.helpers.timestamp_capture.Timestamp_Collector          import Timestamp_Collector

# Decorator
from osbot_utils.helpers.timestamp_capture.decorators.timestamp         import timestamp

# Decorator for dynamic names from function arguments
from osbot_utils.helpers.timestamp_capture.decorators.timestamp_args    import timestamp_args

# Context manager for code blocks
from osbot_utils.helpers.timestamp_capture.context_managers.timestamp_block import timestamp_block

# Analysis (optional - for programmatic access)
from osbot_utils.helpers.timestamp_capture.Timestamp_Collector__Analysis import Timestamp_Collector__Analysis

# Reporting (optional - for custom reports)  
from osbot_utils.helpers.timestamp_capture.Timestamp_Collector__Report   import Timestamp_Collector__Report
```

---

## Usage Patterns

### Pattern 1: Simple Method Profiling

```python
from osbot_utils.helpers.timestamp_capture.Timestamp_Collector  import Timestamp_Collector
from osbot_utils.helpers.timestamp_capture.decorators.timestamp import timestamp

class DataProcessor:
    
    @timestamp
    def process(self, items):
        for item in items:
            self._process_item(item)
    
    @timestamp
    def _process_item(self, item):
        # process single item
        pass

# Profile it
_timestamp_collector_ = Timestamp_Collector(name="data_processing")

with _timestamp_collector_:
    processor = DataProcessor()
    processor.process(my_items)

_timestamp_collector_.print_report()
```

### Pattern 2: Profiling Code Blocks

Use `timestamp_block` for code that isn't in a method:

```python
from osbot_utils.helpers.timestamp_capture.context_managers.timestamp_block import timestamp_block

_timestamp_collector_ = Timestamp_Collector(name="pipeline")

with _timestamp_collector_:
    
    with timestamp_block("phase_1_loading"):
        data = load_data()
    
    with timestamp_block("phase_2_processing"):
        result = process(data)
    
    with timestamp_block("phase_3_saving"):
        save(result)

_timestamp_collector_.print_report()
```

### Pattern 3: Multiple Iterations

```python
_timestamp_collector_ = Timestamp_Collector(name="batch_processing")

with _timestamp_collector_:
    for i, item in enumerate(items):
        with timestamp_block(f"iteration_{i}"):
            processor.process(item)

# Report shows aggregated timings per method
# Plus individual iteration blocks
_timestamp_collector_.print_report()
```

### Pattern 4: Custom Metric Names

By default, `@timestamp` uses the method's qualified name (`__qualname__`). Use `name=` to override with custom, meaningful names:

```python
@timestamp(name="custom.parse.json")
def parse_json(self, data):
    ...

@timestamp(name="custom.parse.xml")
def parse_xml(self, data):
    ...

# Shows as "custom.parse.json" and "custom.parse.xml" in reports
# instead of "MyClass.parse_json" and "MyClass.parse_xml"
```

**Use cases for custom names:**

#### Hierarchical Naming for Pipeline Stages

```python
class DataPipeline:
    
    @timestamp(name="pipeline.stage1.extract")
    def extract(self, source):
        ...
    
    @timestamp(name="pipeline.stage2.transform")
    def transform(self, data):
        ...
    
    @timestamp(name="pipeline.stage3.load")
    def load(self, data, destination):
        ...
```

#### Grouping Related Operations

```python
class FileProcessor:
    
    @timestamp(name="io.read.open_file")
    def open_file(self, path):
        ...
    
    @timestamp(name="io.read.parse_content")
    def parse_content(self, content):
        ...
    
    @timestamp(name="io.write.save_file")
    def save_file(self, path, data):
        ...

# In reports, all io.read.* and io.write.* operations group visually
```

#### Versioning or A/B Testing

```python
@timestamp(name="algorithm.sort.v1_quicksort")
def sort_v1(self, data):
    # Original implementation
    ...

@timestamp(name="algorithm.sort.v2_mergesort")
def sort_v2(self, data):
    # New implementation
    ...

# Easy to compare performance between versions
```

#### Consistent Naming Across Classes

```python
class JsonParser:
    @timestamp(name="parser.parse")          # Same logical operation
    def parse(self, content):
        ...

class XmlParser:
    @timestamp(name="parser.parse")          # Same metric name
    def parse(self, content):
        ...

# Both aggregate under "parser.parse" in reports
# Useful when comparing implementations of same interface
```

#### Dynamic-Looking Names (defined at decoration time)

```python
# Names are fixed at decoration time, but you can use naming conventions
@timestamp(name="handler.request.GET")
def handle_get(self):
    ...

@timestamp(name="handler.request.POST")
def handle_post(self):
    ...

@timestamp(name="handler.request.DELETE")
def handle_delete(self):
    ...
```

**Naming best practices:**

| Pattern | Example | Use Case |
|---------|---------|----------|
| `domain.operation` | `parser.parse` | Simple categorization |
| `domain.category.operation` | `io.read.open_file` | Hierarchical grouping |
| `component.stage.action` | `pipeline.stage1.extract` | Pipeline stages |
| `feature.version.method` | `algorithm.v2.sort` | A/B testing |


### Pattern 5: Dynamic Names from Function Arguments

When a method is called multiple times with different arguments and you need to distinguish each call in reports, use `@timestamp_args`. This interpolates function argument values into the metric name at runtime.
```python
from osbot_utils.helpers.timestamp_capture.decorators.timestamp_args import timestamp_args

class DocumentBuilder:
    
    @timestamp_args(name="link_component({name})")
    def _link_component(self, name: str, root_id: int):
        # Link a component graph to the document
        ...

# Each call is tracked separately:
builder._link_component("head", 1)
builder._link_component("body", 2)
builder._link_component("attrs", 3)
```

**Timeline shows each call distinctly:**
```
20.879ms           ▶ link_component(head)
21.846ms           ◀ link_component(head)
21.860ms           ▶ link_component(body)
22.659ms           ◀ link_component(body)
22.671ms           ▶ link_component(attrs)
23.433ms           ◀ link_component(attrs)
```

**Hotspots show individual breakdowns:**
```
link_component(head)     0.97ms [1 call]
link_component(body)     0.80ms [1 call]
link_component(attrs)    0.76ms [1 call]
```

#### When to use `@timestamp_args` vs `@timestamp`

| Decorator | Name Resolution | Use When |
|-----------|-----------------|----------|
| `@timestamp` | At decoration time (static) | Same name for all calls |
| `@timestamp_args` | At call time (dynamic) | Need to distinguish calls by argument values |

#### Supported Argument Patterns
```python
# Positional arguments
@timestamp_args(name="process.{item_type}")
def process(item_type: str, data: dict):
    ...

# Multiple arguments
@timestamp_args(name="handler.{method}.{path}")
def handle_request(method: str, path: str):
    ...

# Keyword-only arguments (after *)
@timestamp_args(name="config.{env}.{region}")
def configure(*, env: str, region: str = "us-east-1"):
    ...

# Mixed positional and keyword-only
@timestamp_args(name="request.{method}")
def make_request(method: str, *, timeout: int = 30):
    ...

# Using default values (defaults are interpolated too)
@timestamp_args(name="cache.{strategy}")
def cache_data(data: dict, *, strategy: str = "lru"):
    ...
# cache_data({"a": 1}) → "cache.lru"
# cache_data({"a": 1}, strategy="fifo") → "cache.fifo"
```

#### Real-World Example
```python
class Html_MGraph__Document:
    
    @timestamp(name="html_mgraph.document.setup")
    def setup(self):
        self.head_graph  = Html_MGraph__Head().setup()
        self.body_graph  = Html_MGraph__Body().setup()
        self.attrs_graph = Html_MGraph__Attributes().setup()
        
        # Each link is tracked separately
        self._link_component_graph('head', self.head_graph.root_id)
        self._link_component_graph('body', self.body_graph.root_id)
        self._link_component_graph('attrs', self.attrs_graph.root_id)
        return self
    
    @timestamp_args(name="html_mgraph.document._link_component_graph({name})")
    def _link_component_graph(self, name: str, component_root_id: Node_Id):
        # Now each call shows which component in timeline/reports
        ...
```

**Important:** `@timestamp_args` requires at least one `{placeholder}` in the name. For static names, use `@timestamp` instead (lower overhead).


#### Advanced Format Patterns

Since `@timestamp_args` uses Python's standard `.format()` under the hood, you get access to powerful formatting features for free:

**Accessing `self` and Instance Attributes**
```python
class Html_MGraph__Base(Type_Safe):
    
    @timestamp_args(name="html_mgraph.{self.__class__.__name__}.setup")
    def setup(self):
        ...

# When called on subclasses:
# Html_MGraph__Head().setup()   → "html_mgraph.Html_MGraph__Head.setup"
# Html_MGraph__Body().setup()   → "html_mgraph.Html_MGraph__Body.setup"
# Html_MGraph__Styles().setup() → "html_mgraph.Html_MGraph__Styles.setup"
```

This is powerful for base classes where multiple subclasses inherit the same method - each shows its actual runtime type in reports.

**Accessing Instance Properties**
```python
class Processor(Type_Safe):
    name: str = ''
    
    @timestamp_args(name="processor.{self.name}.execute")
    def execute(self, data):
        ...

processor = Processor(name="image_converter")
processor.execute(data)  # → "processor.image_converter.execute"
```

**Format Specifications for Alignment**

Use format specs to ensure consistent column alignment in reports:
```python
@timestamp_args(name="link_component({name:7})")
def _link_component(self, name: str, root_id: int):
    ...

# Results in aligned output:
# link_component(head   )
# link_component(body   )
# link_component(attrs  )
# link_component(scripts)
# link_component(styles )
```

**Available Format Specs**

| Spec | Input | Result | Use Case |
|------|-------|--------|----------|
| `{name}` | `"head"` | `"head"` | Default |
| `{name:10}` | `"head"` | `"head      "` | Fixed width |
| `{name:<10}` | `"head"` | `"head      "` | Left align |
| `{name:>10}` | `"head"` | `"      head"` | Right align |
| `{name:^10}` | `"head"` | `"   head   "` | Center |
| `{id:04d}` | `42` | `"0042"` | Zero-padded numbers |
| `{val:.2f}` | `3.14159` | `"3.14"` | Decimal places |

**Combining Patterns**
```python
class DataPipeline(Type_Safe):
    pipeline_id: str = ''
    
    @timestamp_args(name="pipeline.{self.pipeline_id}.stage.{stage_name:12}")
    def run_stage(self, stage_name: str, data: dict):
        ...

pipeline = DataPipeline(pipeline_id="etl_001")
pipeline.run_stage("extract", data)    # → "pipeline.etl_001.stage.extract     "
pipeline.run_stage("transform", data)  # → "pipeline.etl_001.stage.transform   "
pipeline.run_stage("load", data)       # → "pipeline.etl_001.stage.load        "
```

**Common Patterns Summary**

| Pattern | Example | Use Case |
|---------|---------|----------|
| `{self.__class__.__name__}` | `MyClass` | Polymorphic methods in base classes |
| `{self.name}` | `my_instance` | Instance identification |
| `{arg:N}` | `value     ` | Column alignment in reports |
| `{self.id}.{operation}` | `proc_1.execute` | Namespaced operations |

### Pattern 6: Programmatic Analysis

```python
from osbot_utils.helpers.timestamp_capture.Timestamp_Collector__Analysis import Timestamp_Collector__Analysis

_timestamp_collector_ = Timestamp_Collector()

with _timestamp_collector_:
    do_work()

# Get analysis object
analysis = Timestamp_Collector__Analysis(collector=_timestamp_collector_)

# Get method timings as dict
timings = analysis.get_method_timings()
for name, timing in timings.items():
    print(f"{name}: {timing.total_ns / 1_000_000:.2f}ms ({timing.call_count} calls)")

# Get hotspots (sorted by self-time)
hotspots = analysis.get_hotspots(top_n=5)
for timing in hotspots:
    print(f"Hotspot: {timing.name} - {timing.self_ns / 1_000_000:.2f}ms self-time")

# Get timings sorted by total time
by_total = analysis.get_timings_by_total()

# Get timings sorted by call count
by_calls = analysis.get_timings_by_call_count()
```

### Pattern 7: Test Performance Assertions

```python
def test_process_performance(self):
    _timestamp_collector_ = Timestamp_Collector(name="perf_test")
    
    with _timestamp_collector_:
        processor.process(test_data)
    
    analysis = Timestamp_Collector__Analysis(collector=_timestamp_collector_)
    timings = analysis.get_method_timings()
    
    # Assert specific methods complete within time budget
    assert timings['_parse'].total_ns < 10_000_000      # < 10ms
    assert timings['_transform'].total_ns < 50_000_000  # < 50ms
    
    # Assert total time
    assert _timestamp_collector_.total_duration_ms() < 100  # < 100ms
```

---

## Report Types

### print_report() - Comprehensive Timing Report

```
====================================================================================================
Timestamp Report: my_workflow
====================================================================================================

  Total Duration : 156.78 ms
  Entry Count    : 324
  Methods Traced : 6

Method Timings (sorted by total time):
----------------------------------------------------------------------------------------------------
Method                                             Calls      Total       Self      Avg    %Total
----------------------------------------------------------------------------------------------------
MyProcessor.process                                    1   145.23ms   12.34ms 145.230ms   92.6%
MyProcessor._transform                                 1    89.45ms   89.45ms  89.450ms   57.0%
MyProcessor._parse                                     1    32.12ms   32.12ms  32.120ms   20.5%
MyProcessor._output                                    1    11.32ms   11.32ms  11.320ms    7.2%
----------------------------------------------------------------------------------------------------

====================================================================================================
```

**Key columns:**
- **Total**: Time including all child method calls
- **Self**: Time excluding child method calls (actual work in this method)
- **Avg**: Average time per call
- **%Total**: Percentage of total captured time

### print_hotspots() - Top Methods by Self-Time

```
================================================================================
Top 10 Hotspots (by self-time)
================================================================================
   1. _transform                               89.45ms (57.0%) [1 calls]
   2. _parse                                   32.12ms (20.5%) [1 calls]
   3. MyProcessor.process                      12.34ms ( 7.9%) [1 calls]
   4. _output                                  11.32ms ( 7.2%) [1 calls]
================================================================================
```

**Use this to find where time is actually spent**, not just which methods take longest (which may be due to calling slow children).

### print_timeline() - Chronological Execution View

```
================================================================================
Execution Timeline
================================================================================
     0.000ms ▶ Pipeline.run
     0.015ms   ▶ Pipeline._load_data
     5.234ms     ▶ FileReader.read
     8.891ms       ▶ FileReader._open_file
    12.456ms       ◀ FileReader._open_file
    12.478ms       ▶ FileReader._parse_content
    45.123ms         ▶ Parser.parse_json
    67.890ms         ◀ Parser.parse_json
    67.912ms       ◀ FileReader._parse_content
    67.934ms     ◀ FileReader.read
    67.956ms   ◀ Pipeline._load_data
    67.978ms   ▶ Pipeline._transform
    68.001ms     ▶ Transformer.apply
    68.023ms       ▶ Transformer._validate
    72.345ms       ◀ Transformer._validate
    72.367ms       ▶ Transformer._process
   145.678ms         ▶ Transformer._process_batch
   189.234ms         ◀ Transformer._process_batch
   189.256ms       ◀ Transformer._process
   189.278ms     ◀ Transformer.apply
   189.300ms   ◀ Pipeline._transform
   189.322ms   ▶ Pipeline._save_output
   195.456ms   ◀ Pipeline._save_output
   195.478ms ◀ Pipeline.run
================================================================================
```

**Key features:**
- **Visual nesting**: Indentation shows call depth at a glance
- **Entry/exit markers**: `▶` for enter, `◀` for exit
- **Timestamp alignment**: Easy to calculate duration by scanning vertically
- **Unlimited depth**: Supports arbitrary nesting levels

**Use this to:**
- Understand execution flow and method call hierarchy
- Identify unexpected call sequences
- Spot methods that are called more times than expected
- Visualize where time is spent in nested operations

---

## Understanding Self-Time vs Total-Time

```
process() ─────────────────────────────────────────────────────── Total: 100ms
    │
    ├── _parse() ─────────────────── Total: 30ms, Self: 30ms (leaf)
    │
    ├── _transform() ─────────────── Total: 50ms, Self: 20ms
    │       │
    │       └── _helper() ────────── Total: 30ms, Self: 30ms (leaf)
    │
    └── _output() ────────────────── Total: 15ms, Self: 15ms (leaf)
    
    process self-time = 100 - 30 - 50 - 15 = 5ms (orchestration overhead)
```

**Self-time** is the actual time spent in that method's code, excluding time in child calls. This is what you want to optimize.

---

## Best Practices

### DO: Decorate Entry Points and Key Methods

```python
class Pipeline:
    
    @timestamp                    # ✅ Entry point
    def run(self, data):
        ...
    
    @timestamp                    # ✅ Key processing step
    def _major_transform(self, data):
        ...
    
    def _tiny_helper(self, x):    # ✅ Skip tiny helpers
        return x + 1
```

### DO: Use Descriptive Collector Names

```python
# ✅ Good - descriptive
_timestamp_collector_ = Timestamp_Collector(name="html_to_mgraph_conversion")
_timestamp_collector_ = Timestamp_Collector(name="api_request_handling")

# ❌ Bad - not descriptive
_timestamp_collector_ = Timestamp_Collector(name="test")
_timestamp_collector_ = Timestamp_Collector()  # defaults to "default"
```

### DO: Use timestamp_block for Phases

```python
with _timestamp_collector_:
    with timestamp_block("initialization"):
        setup()
    
    with timestamp_block("main_processing"):
        process()
    
    with timestamp_block("cleanup"):
        teardown()
```

### DON'T: Decorate Micro-Functions in Hot Loops

```python
class Calculator:
    
    @timestamp                    # ✅ Decorate outer method
    def sum_all(self, items):
        total = 0
        for item in items:
            total = self._add(item, total)  # Called 1M times
        return total
    
    def _add(self, a, b):         # ❌ DON'T decorate - called too frequently
        return a + b
```

### DON'T: Forget the Magic Variable Name

```python
# ❌ WRONG - collector won't be found
collector = Timestamp_Collector()
with collector:
    my_decorated_method()  # @timestamp won't find it!

# ✅ CORRECT
_timestamp_collector_ = Timestamp_Collector()
with _timestamp_collector_:
    my_decorated_method()  # @timestamp finds it via stack walk
```

---

## Performance Characteristics

| Scenario | Overhead | Production Safe? |
|----------|----------|------------------|
| @timestamp, no collector | ~3 μs | ✅ Yes |
| @timestamp, with collector | ~8 μs | ✅ Yes (for methods >100μs) |
| Nested decorators (N levels) | N × overhead | ✅ Scales linearly |
| @timestamp_args, with collector | ~10 μs | ✅ Yes (slight overhead for arg binding) |

**Rule of thumb**: If your method takes >100μs, the 8μs capture overhead is <8% - acceptable for most scenarios including production profiling.

---

## Common Integration Scenarios

### Scenario: Profiling a Conversion Pipeline

```python
from osbot_utils.helpers.timestamp_capture.Timestamp_Collector          import Timestamp_Collector
from osbot_utils.helpers.timestamp_capture.Timestamp_Collector__Report  import Timestamp_Collector__Report
from osbot_utils.helpers.timestamp_capture.decorators.timestamp         import timestamp

class Html_To_MGraph_Converter:
    
    @timestamp
    def convert(self, html: str):
        doc = self._create_document()
        self._parse_html(html)
        self._build_body_graph(doc)
        self._build_attrs_graph(doc)
        return doc
    
    @timestamp
    def _create_document(self):
        ...
    
    @timestamp
    def _parse_html(self, html):
        ...
    
    @timestamp
    def _build_body_graph(self, doc):
        for element in self.soup.find_all():
            self._process_element(element)
    
    @timestamp
    def _process_element(self, element):
        # Called many times - will show aggregate stats
        ...
    
    @timestamp
    def _build_attrs_graph(self, doc):
        ...

# Usage
def profile_conversion(html_content):
    _timestamp_collector_ = Timestamp_Collector(name="html_conversion")
    
    with _timestamp_collector_:
        converter = Html_To_MGraph_Converter()
        doc = converter.convert(html_content)
    
    report = Timestamp_Collector__Report(collector=_timestamp_collector_)
    report.print_report()
    report.print_hotspots()
    
    return doc
```

### Scenario: Comparing Two Implementations

```python
def compare_implementations(data):
    # Profile implementation A
    _timestamp_collector_ = Timestamp_Collector(name="impl_A")
    with _timestamp_collector_:
        result_a = implementation_a(data)
    time_a = _timestamp_collector_.total_duration_ms()
    
    # Profile implementation B
    _timestamp_collector_ = Timestamp_Collector(name="impl_B")
    with _timestamp_collector_:
        result_b = implementation_b(data)
    time_b = _timestamp_collector_.total_duration_ms()
    
    print(f"Implementation A: {time_a:.2f}ms")
    print(f"Implementation B: {time_b:.2f}ms")
    print(f"Speedup: {time_a/time_b:.2f}x")
```

### Scenario: Continuous Performance Monitoring

```python
class PerformanceMonitor:
    
    def __init__(self):
        self.history = []
    
    def profile_operation(self, operation_func, *args, **kwargs):
        _timestamp_collector_ = Timestamp_Collector(name="monitored_op")
        
        with _timestamp_collector_:
            result = operation_func(*args, **kwargs)
        
        self.history.append({
            'timestamp'   : time.time(),
            'duration_ms' : _timestamp_collector_.total_duration_ms(),
            'entry_count' : _timestamp_collector_.entry_count(),
        })
        
        return result
    
    def get_average_duration(self):
        if not self.history:
            return 0
        return sum(h['duration_ms'] for h in self.history) / len(self.history)
```

---

## Troubleshooting

### Problem: Decorator Not Capturing Anything

**Cause**: Collector variable not named `_timestamp_collector_`

```python
# ❌ Won't work
my_collector = Timestamp_Collector()

# ✅ Will work
_timestamp_collector_ = Timestamp_Collector()
```

### Problem: Methods Show 0ms Self-Time

**Cause**: Method only calls other decorated methods, does no work itself

```python
@timestamp
def orchestrator(self):
    self._step1()  # All time spent in children
    self._step2()
    self._step3()
    # self-time ≈ 0ms is correct - this method just orchestrates
```

### Problem: Too Many Entries in Report

**Cause**: Decorating methods called in loops

**Solution**: Only decorate higher-level methods, or use `timestamp_block` for the loop

```python
# Instead of decorating _process_item called 1000x
with timestamp_block("process_all_items"):
    for item in items:
        self._process_item(item)  # Don't decorate this
```

### Problem: Can't Find Collector in Deeply Nested Code

**Cause**: Stack depth exceeds `MAX_STACK_DEPTH` (default: 50)

**Solution**: Increase max_depth or restructure code

```python
# In timestamp_collector__config.py
MAX_STACK_DEPTH = 100  # Increase if needed
```

### Problem: Can't Distinguish Multiple Calls to Same Method

**Cause**: Using `@timestamp` on a method called with different arguments
```python
# ❌ All 5 calls show as same name
@timestamp(name="link_component")
def _link_component(self, name: str, root_id: int):
    ...
```

**Solution**: Use `@timestamp_args` to include argument values in the name
```python
# ✅ Each call shows distinct name
@timestamp_args(name="link_component({name})")
def _link_component(self, name: str, root_id: int):
    ...
```

---

## Summary Checklist

When adding timestamp capture to a codebase:

- [ ] Import `@timestamp` decorator and `Timestamp_Collector`
- [ ] Add `@timestamp` to key methods (entry points, major processing steps)
- [ ] Use `@timestamp(name="...")` for hierarchical/grouped naming when helpful
- [ ] Use `@timestamp_args(name="method({arg})")` when you need to distinguish calls by argument values
- [ ] Skip tiny utility functions and hot-loop internals
- [ ] Use `timestamp_block` for code phases not in methods
- [ ] Name collector variable exactly `_timestamp_collector_`
- [ ] Give collector a descriptive name
- [ ] Use `print_hotspots()` to find actual bottlenecks (self-time)
- [ ] Use `print_timeline()` to understand execution flow
- [ ] Use `get_method_timings()` for programmatic analysis
- [ ] Remember: decorators can stay in production (~3μs overhead when inactive)